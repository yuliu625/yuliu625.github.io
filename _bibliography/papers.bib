---
---

@article{Liu2025NetworkEffects,
  selected  = {true},
	title     = {When Machines Meet Each Other: Network Effects and the Strategic Role of History in Multi-Agent AI Systems},
	author    = {Liu, Yu and Li, Wenwen and Dou, Yifan and Ye, Guangnan},
	year      = {2025},
	month     = {October},
	day       = {06},
	journal   = {SSRN Working Paper},
  doi       = {10.2139/ssrn.5578230},
	note      = {Available at SSRN: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5578230},
	abstract  = {As artificial intelligence (AI) enters the agentic era, large language models (LLMs) are increasingly deployed as autonomous agents that interact with one another rather than operate in isolation. This shift raises a fundamental question: how do machine agents behave in interdependent environments where outcomes depend not only on their own choices but also on the coordinated expectations of peers? To address this question, we study LLM agents in a canonical network-effect game, where economic theory predicts convergence to a fulfilled expectation equilibrium (FEE). We design an experimental framework in which 50 heterogeneous GPT-5-based agents repeatedly interact under systematically varied network-effect strengths, price trajectories, and decision-history lengths. The results reveal that LLM agents systematically diverge from FEE: they underestimate participation at low prices, overestimate at high prices, and sustain persistent dispersion. Crucially, the way history is structured emerges as a design lever. Simple monotonic histories—where past outcomes follow a steady upward or downward trend—help stabilize coordination, whereas non-monotonic histories amplify divergence and path dependence. Regression analyses at the individual level further show that price is the dominant driver of deviation, history moderates this effect, and network effects amplify contextual distortions. Together, these findings advance machine behavior research by providing the first systematic evidence on multi-agent AI systems under network effects and offer guidance for configuring such systems in practice.},
  keywords  = {Multi-Agent System, History, Agentic Learning, Network Effects},
  description = {The working paper is under submission.}
}

@inproceedings{Liu2025Swaib,
  selected  = {true},
  title     = {Beyond Rationality: Network Effects, History, and Machine Optimism in Multi-Agents},
  author    = {Liu, Yu and Li, Wenwen and Dou, Yifan and Ye, Guangnan},
  year      = {2025},
  month     = {July},
  booktitle = {The Second Summer Workshop on AI for Business},
  abstract  = {Understanding decision-making in multi-AI-agent frameworks is crucial for analyzing strategic interactions in network-effect-driven contexts. This study investigates how AI agents navigate network-effect games, where individual payoffs depend on peer participation—a context underexplored in multi-agent systems despite its real-world prevalence. We introduce a novel workflow design using large language model (LLM)-based agents in repeated decision-making scenarios, systematically manipulating price trajectories (fixed, ascending, descending, random) and network-effect strength. Our key findings include: First, without historical data, agents fail to infer equilibrium. Second, ordered historical sequences (e.g., escalating prices) enable partial convergence under weak network effects but strong effects trigger persistent “AI optimism”—agents overestimate participation despite contradictory evidence. Third, randomized history disrupts convergence entirely, demonstrating that temporal coherence in data shapes LLMs' reasoning, unlike humans. These results highlight a paradigm shift: in AI-mediated systems, equilibrium outcomes depend not just on incentives, but on how history is curated, which is impossible for human.},
  keywords  = {Network effects, Multi-Agent System, Agentic Learning, AI Optimism, History},
  code      = {https://github.com/yuliu625/World-of-Six},
  description = {This study investigates how Large Language Model (LLM) agents navigate network-effect games, finding that their ability to reach theoretical equilibrium is critically dependent on the temporal coherence and structure of historical data, with strong network effects triggering persistent "AI optimism" that overrides rational inference.}
}


